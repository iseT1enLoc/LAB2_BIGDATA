{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ff9bc2cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff9bc2cc",
        "outputId": "27317c11-4582-4685-e5a8-4ce86449c41a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/11/25 21:50:44 WARN Utils: Your hostname, tienloc-laptop resolves to a loopback address: 127.0.1.1; using 192.168.31.171 instead (on interface wlp0s20f3)\n",
            "25/11/25 21:50:44 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
            "25/11/25 21:50:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Init successfully\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "import os\n",
        "\n",
        "# Init Spark Context\n",
        "conf = SparkConf().setAppName(\"MovieRatingsAnalytics\").setMaster(\"local[*]\")\n",
        "sc = SparkContext.getOrCreate(conf=conf)\n",
        "spark = SparkSession.builder.appName(\"MovieRatingsAnalytics\").getOrCreate()\n",
        "\n",
        "print(\"Init successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d6098792",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6098792",
        "outputId": "c46ea52d-3705-4303-cc58-626d0221485f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of rating from file 1: 84\n",
            "Total number of rating from file 2: 100\n",
            "\n",
            "Data ratings_1.txt (5 first lines):\n",
            "7,1020,4.5,1577836800\n",
            "23,1015,3.5,1577923200\n",
            "45,1030,4.0,1578009600\n",
            "12,1047,3.0,1578096000\n",
            "38,1012,4.5,1578182400\n",
            "\n",
            "Data ratings_2.txt (5 first lines:\n",
            "12,1012,3.5,1577837800\n",
            "34,1039,4.0,1577924200\n",
            "27,1043,4.5,1578010600\n",
            "8,1020,3.0,1578097000\n",
            "19,1050,4.0,1578183400\n"
          ]
        }
      ],
      "source": [
        "data_path = \"file:///home/tienloc/lab2bigdata/data/\"\n",
        "# Read data from ratings_1.txt và ratings_2.txt\n",
        "ratings_1_rdd = sc.textFile(data_path + \"ratings_1.txt\")\n",
        "ratings_2_rdd = sc.textFile(data_path + \"ratings_2.txt\")\n",
        "\n",
        "print(f\"Total number of rating from file 1: {ratings_1_rdd.count()}\")\n",
        "print(f\"Total number of rating from file 2: {ratings_2_rdd.count()}\")\n",
        "\n",
        "# Show sample data\n",
        "print(\"\\nData ratings_1.txt (5 first lines):\")\n",
        "for line in ratings_1_rdd.take(5):\n",
        "    print(line)\n",
        "\n",
        "print(\"\\nData ratings_2.txt (5 first lines:\")\n",
        "for line in ratings_2_rdd.take(5):\n",
        "    print(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3dce4afb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dce4afb",
        "outputId": "9801fbce-1975-4771-e493-ac5f07dadc92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ratings 1 parsed with year (5 records):\n",
            "Year: 2000, Rating: 4.5\n",
            "Year: 2000, Rating: 3.5\n",
            "Year: 2000, Rating: 4.0\n",
            "Year: 2000, Rating: 3.0\n",
            "Year: 2000, Rating: 4.5\n",
            "\n",
            "Ratings 2 parsed with year (5 records):\n",
            "Year: 2000, Rating: 3.5\n",
            "Year: 2000, Rating: 4.0\n",
            "Year: 2000, Rating: 4.5\n",
            "Year: 2000, Rating: 3.0\n",
            "Year: 2000, Rating: 4.0\n",
            "\n",
            "Total number of ratings files: 184\n",
            "\n",
            "Years existing in dataset: [2000]\n",
            "The lastest year: 2000\n",
            "The earliest year: 2000\n"
          ]
        }
      ],
      "source": [
        "# Process data ratings with timestamp to get year\n",
        "# Parse ratings: UserID, MovieID, Rating, Timestamp\n",
        "def parse_rating_with_year(line):\n",
        "    parts = line.split(',')\n",
        "    rating = float(parts[2])\n",
        "    timestamp = int(parts[3])\n",
        "\n",
        "    # Convert timestamp into year\n",
        "    try:\n",
        "        year = datetime.fromtimestamp(timestamp).year\n",
        "    except:\n",
        "        year = 2000  # Default year if fail to parse\n",
        "\n",
        "    return (year, rating)\n",
        "\n",
        "# Parse 2 ratings files\n",
        "ratings_1_parsed = ratings_1_rdd.map(parse_rating_with_year)\n",
        "ratings_2_parsed = ratings_2_rdd.map(parse_rating_with_year)\n",
        "\n",
        "print(\"Ratings 1 parsed with year (5 records):\")\n",
        "for rating in ratings_1_parsed.take(5):\n",
        "    print(f\"Year: {rating[0]}, Rating: {rating[1]}\")\n",
        "\n",
        "print(\"\\nRatings 2 parsed with year (5 records):\")\n",
        "for rating in ratings_2_parsed.take(5):\n",
        "    print(f\"Year: {rating[0]}, Rating: {rating[1]}\")\n",
        "\n",
        "# Merge 2 RDD rating files together\n",
        "all_ratings = ratings_1_parsed.union(ratings_2_parsed)\n",
        "print(f\"\\nTotal number of ratings files: {all_ratings.count()}\")\n",
        "\n",
        "# Determine scope of year\n",
        "years_sample = all_ratings.map(lambda x: x[0]).distinct().collect()\n",
        "years_sample.sort()\n",
        "print(f\"\\nYears existing in dataset: {years_sample}\")\n",
        "print(f\"The lastest year: {min(years_sample)}\")\n",
        "print(f\"The earliest year: {max(years_sample)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8aed6f45",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aed6f45",
        "outputId": "5ab3b253-da4c-4aa9-cb3c-7f8bd5cf3db2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2000 - TotalRatings: 184, AverageRating: 3.75\n"
          ]
        }
      ],
      "source": [
        "# Calculating rating and number of ratings per year\n",
        "# (year, rating) -> (year, (rating, 1))\n",
        "year_ratings_with_count = all_ratings.map(lambda x: (x[0], (x[1], 1)))\n",
        "\n",
        "# Reduce by key to calculating sum of rating and total rating per year\n",
        "# (year, (sum_ratings, total_count))\n",
        "year_stats = year_ratings_with_count.reduceByKey(lambda a, b: (a[0] + b[0], a[1] + b[1]))\n",
        "\n",
        "# Calculating average point for each year and show result\n",
        "def calculate_year_average(record):\n",
        "    year, (sum_ratings, count) = record\n",
        "    average_rating = sum_ratings / count\n",
        "    return (year, (count, average_rating))  # (year, (total_ratings, average_rating))\n",
        "\n",
        "year_results = year_stats.map(calculate_year_average)\n",
        "\n",
        "# Order ascending year\n",
        "sorted_year_results = year_results.sortByKey()\n",
        "\n",
        "# show result\n",
        "all_years = sorted_year_results.collect()\n",
        "\n",
        "for year, (total_ratings, avg_rating) in all_years:\n",
        "    print(f\"{year} - TotalRatings: {total_ratings}, AverageRating: {avg_rating:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1403784f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1403784f",
        "outputId": "e5b71400-f293-42e4-8c02-a460c3111980"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stopping Spark Context và Spark Session.\n"
          ]
        }
      ],
      "source": [
        "# Clean resources\n",
        "sc.stop()\n",
        "spark.stop()\n",
        "print(\"Stopping Spark Context và Spark Session.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
